{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98414a4",
   "metadata": {},
   "source": [
    "### Q1. What is the mathematical formula for a linear SVM?\n",
    "\n",
    "Given a training dataset with features xᵢ and corresponding binary labels yᵢ (where yᵢ is either +1 or -1):\n",
    "    f(x) = w · x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cbe88",
   "metadata": {},
   "source": [
    "### Q2. What is the objective function of a linear SVM?\n",
    "\n",
    "The objective function of a linear Support Vector Machine (SVM) is the one that needs to be minimized during the training process. The goal is to find the optimal hyperplane that separates the two classes while maximizing the margin between them.\n",
    "\n",
    "The objective function of a linear SVM is represented as follows:\n",
    "\n",
    "Minimize: ½ ||w||²\n",
    "\n",
    "Subject to: yᵢ(w · xᵢ + b) ≥ 1 for all training samples (xᵢ, yᵢ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b101f9",
   "metadata": {},
   "source": [
    "### Q3. What is the kernel trick in SVM?\n",
    "\n",
    "The kernel trick is a fundamental concept in Support Vector Machine (SVM) algorithms that allows SVMs to efficiently handle non-linearly separable data by implicitly transforming the input features into a higher-dimensional space. The kernel trick enables SVMs to find a linear decision boundary in this higher-dimensional space, which corresponds to a non-linear decision boundary in the original feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84418549",
   "metadata": {},
   "source": [
    "### Q4. What is the role of support vectors in SVM Explain with example\n",
    "\n",
    "In Support Vector Machines (SVM), support vectors play a critical role in defining the decision boundary (hyperplane) and making accurate predictions. Support vectors are the data points that are closest to the decision boundary, and they have a significant impact on the SVM's model because they define the margin and influence the final classification result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f248f",
   "metadata": {},
   "source": [
    "### Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in SVM?\n",
    "\n",
    "**Hyperplane:**\n",
    "The hyperplane is a flat (d-1)-dimensional plane that separates the data points of two different classes. In a two-dimensional feature space, the hyperplane is a line. The equation of the hyperplane is given by:\n",
    "w · x + b = 0\n",
    "\n",
    "Where w is the weight vector (normal to the hyperplane), x is the input feature vector, and b is the bias term.\n",
    "\n",
    "**Marginal Plane:**\n",
    "The marginal plane is a parallel plane that runs closest to the hyperplane and is equidistant from the support vectors of both classes. It defines the margin, which is the distance between the two marginal planes. In a two-dimensional feature space, the marginal planes are lines.\n",
    "\n",
    "**Hard Margin SVM:**\n",
    "In Hard Margin SVM, the goal is to find a hyperplane that perfectly separates the two classes, and no data points are allowed to violate the margin or lie within it. This means that all data points should be classified correctly, and there should be no misclassifications. Hard Margin SVM is only applicable when the data is linearly separable.\n",
    "\n",
    "**Soft Margin SVM:**\n",
    "In Soft Margin SVM, the goal is to find a hyperplane that separates the two classes while allowing some misclassifications. Soft Margin SVM is applicable when the data is not perfectly separable, or there are outliers. The regularization parameter C controls the trade-off between maximizing the margin and allowing misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2072ff0",
   "metadata": {},
   "source": [
    "### Q6. SVM Implementation through Iris dataset.\n",
    "\n",
    "- Load the iris dataset from the scikit-learn library and split it into a training set and a testing setl\n",
    "- Train a linear SVM classifier on the training set and predict the labels for the testing setl\n",
    "- Compute the accuracy of the model on the testing setl\n",
    "- Plot the decision boundaries of the trained model using two of the featuresl\n",
    "- Try different values of the regularisation parameter C and see how it affects the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76bbced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757187df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47a010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29ba6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1225c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453c2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a204d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c815a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68262122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a53399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74018af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# C = 0.1\n",
    "svc = SVC(kernel='linear',C=0.1)\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a96d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# C = 0.01\n",
    "svc = SVC(kernel='linear',C=0.01)\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5bf8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# C = 10\n",
    "svc = SVC(kernel='linear',C=10)\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998429dd",
   "metadata": {},
   "source": [
    "- #### So we can coclude that C = 1 is best for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
