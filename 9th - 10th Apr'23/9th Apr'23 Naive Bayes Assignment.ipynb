{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c45cff",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?\n",
    "\n",
    "Bayes' theorem, also known as Bayes' rule or Bayes' law, is a fundamental concept in probability theory and statistics. It describes how to update the probability of a hypothesis based on new evidence or information. The theorem is named after the Reverend Thomas Bayes, an English statistician and philosopher, who introduced it in the 18th century.\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, and artificial intelligence. In machine learning, it plays a crucial role in Bayesian inference and Bayesian modeling, particularly in algorithms like Naive Bayes classifiers.\n",
    "\n",
    "The theorem provides a framework for updating beliefs or probabilities based on new information, making it a powerful tool for reasoning under uncertainty. It allows us to make better-informed decisions by incorporating new evidence into our existing knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171e1f4",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "p(A|B) = (p(A)*p(B|A) / p(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66475a79",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "\n",
    "Bayes' theorem is used in various practical applications across different fields. Some common use cases include:\n",
    "\n",
    "**Spam Filtering:** Bayes' theorem is employed in email spam filtering. The algorithm calculates the probability that an email is spam given the occurrence of certain words or features in the email. It updates these probabilities based on a labeled dataset of spam and non-spam emails to make more accurate spam classification.\n",
    "\n",
    "**Medical Diagnosis:** In healthcare, Bayes' theorem is used to assess the probability of a patient having a particular disease based on their symptoms and medical test results. It helps doctors make more informed decisions about diagnosis and treatment.\n",
    "\n",
    "**Text Classification:** Bayes' theorem is utilized in natural language processing tasks such as text classification. It helps classify documents into predefined categories based on the occurrence of specific words or patterns in the text.\n",
    "\n",
    "**Sentiment Analysis:** In sentiment analysis, Bayes' theorem is applied to determine the sentiment (positive, negative, or neutral) of a piece of text (e.g., customer reviews, social media posts) based on the occurrence of certain words or phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05e309",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Bayes' theorem and conditional probability are closely related concepts in probability theory. In fact, Bayes' theorem is a fundamental result derived from conditional probability.\n",
    "\n",
    "Conditional Probability:\n",
    "Conditional probability measures the likelihood of an event occurring given that another event has already occurred. It is denoted as  p(A|B), which represents the probability of event A happening, given that event B has occurred.\n",
    "\n",
    "Bayes' Theorem:\n",
    "Bayes' theorem provides a way to update the probability of a hypothesis or event based on new evidence or information. It is expressed as:\n",
    "p(A|B) = (p(A)*p(B|A) / p(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa04dbf",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Choosing the most appropriate type of Naive Bayes classifier for a given problem depends on the nature of the data and the underlying assumptions about the relationship between features and class labels. The three common types of Naive Bayes classifiers are Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here are some guidelines to help you decide which one to use:\n",
    "\n",
    "**Gaussian Naive Bayes:**\n",
    "\n",
    "- Use when your features are continuous (real-valued) and assumed to follow a Gaussian (normal) distribution.\n",
    "- Applicable for problems with numerical features such as height, weight, temperature, etc.\n",
    "-Assumes that the features are continuous and the likelihood follows a normal distribution.\n",
    "\n",
    "**Multinomial Naive Bayes:**\n",
    "\n",
    "- Use when dealing with discrete features (e.g., word counts, document frequency, etc.).\n",
    "- Commonly used for text classification problems, where the features are the frequency of words in a document or their presence/absence.\n",
    "- Well-suited for problems involving count data, such as word frequency in a document.\n",
    "\n",
    "**Bernoulli Naive Bayes:**\n",
    "\n",
    "- Use when dealing with binary features or presence/absence data (e.g., word occurrence in a document).\n",
    "- Appropriate for text classification tasks with binary feature representation (word present or absent).\n",
    "- Works well when the features are binary indicators of whether a particular event occurred or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ff8ac",
   "metadata": {},
   "source": [
    "### Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "    \n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205162b5",
   "metadata": {},
   "source": [
    "To predict the class of the new instance (X1 = 3 and X2 = 4) using Naive Bayes, we need to calculate the likelihood probabilities for each class based on the given frequency table and assume equal prior probabilities for each class. Then, we use Bayes' theorem to compute the posterior probabilities for both classes and choose the class with the higher posterior probability.\n",
    "\n",
    "Let's go through the steps to calculate the probabilities for each class:\n",
    "\n",
    "Step 1: Calculate Prior Probabilities (P(A) and P(B)):\n",
    "Since equal prior probabilities are assumed for each class,\n",
    "\n",
    "Step 2: Calculate Likelihood Probabilities (P(X1|A), P(X2|A), P(X1|B), and P(X2|B)):\n",
    "We use the given frequency table to calculate the probabilities for each feature value in each class.\n",
    "\n",
    "Step 3: Calculate the Evidence Probability (P(X1=3, X2=4)):\n",
    "The evidence probability is the probability of observing the new instance with X1 = 3 and X2 = 4. We can calculate this by summing up the likelihood probabilities for both classes, weighted by their prior probabilities:\n",
    "    \n",
    "Step 4: Calculate Posterior Probabilities (P(A|X1=3, X2=4) and P(B|X1=3, X2=4)):\n",
    "Now, we can use Bayes' theorem to compute the posterior probabilities for each class:\n",
    "\n",
    "Step 5: Make the Prediction:\n",
    "Finally, we compare the posterior probabilities and choose the class with the higher probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
